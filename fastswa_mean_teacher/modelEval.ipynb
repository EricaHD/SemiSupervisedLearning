{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "from mean_teacher import datasets, architectures\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "to_image = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "           1112955 p40_4,p10    ssm_c   ijh216 PD       0:00      1 (Priority)\r\n",
      "           1112956 p40_4,p10     ss_c   ijh216 PD       0:00      1 (Priority)\r\n",
      "           1112947    c32_38 jupyterC   ijh216  R      46:14      1 c36-03\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u ijh216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel 1079531  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = datasets.__dict__['sslMini']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model_arch, pretrained_model_path, state_dict, cuda=True):\n",
    "        # Load pretrained model\n",
    "        pretrained_model = torch.load(f=pretrained_model_path, map_location=\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in pretrained_model[state_dict].items():\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[name] = v\n",
    "\n",
    "        # Load pre-trained weights in current model\n",
    "        with torch.no_grad():\n",
    "            model_arch.load_state_dict(new_state_dict, strict=True)\n",
    "\n",
    "        # Debug loading\n",
    "        #print('Parameters found in pretrained model:')\n",
    "        pretrained_layers = new_state_dict.keys()\n",
    "        #for l in pretrained_layers:\n",
    "        #    print('\\t' + l)\n",
    "        #print('')\n",
    "\n",
    "        for name, module in model_arch.state_dict().items():\n",
    "            if name in pretrained_layers:\n",
    "                assert torch.equal(new_state_dict[name].cpu(), module.cpu())\n",
    "                #print('{} have been loaded correctly in current model.'.format(name))\n",
    "            else:\n",
    "                raise ValueError(\"state_dict() keys do not match\")\n",
    "                \n",
    "        return model_arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "evaldir = \"/scratch/ehd255/ssl_data_96/supervised/val\"\n",
    "\n",
    "eval_loader = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(evaldir, dataset_config['eval_transformation']),\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2,\n",
    "                                              #pin_memory=True,\n",
    "                                              drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.325.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.load(f=pretrained_model_path, map_location=\"cuda\" if False else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shake(Function):\n",
    "    @classmethod\n",
    "    def forward(cls, ctx, inp1, inp2, training):\n",
    "        assert inp1.size() == inp2.size()\n",
    "        gate_size = [inp1.size()[0], *itertools.repeat(1, inp1.dim() - 1)]\n",
    "        gate = inp1.new(*gate_size)\n",
    "        if training:\n",
    "            gate.uniform_(0, 1)\n",
    "        else:\n",
    "            gate.fill_(0.5)\n",
    "        return inp1 * gate + inp2 * (1. - gate)\n",
    "\n",
    "    @classmethod\n",
    "    def backward(cls, ctx, grad_output):\n",
    "        grad_inp1 = grad_inp2 = grad_training = None\n",
    "        gate_size = [grad_output.size()[0], *itertools.repeat(1,\n",
    "                                                              grad_output.dim() - 1)]\n",
    "        gate = grad_output.detach().new(*gate_size).uniform_(0, 1)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_inp1 = grad_output * gate\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_inp2 = grad_output * (1 - gate)\n",
    "        assert not ctx.needs_input_grad[2]\n",
    "        return grad_inp1, grad_inp2, grad_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'arch', 'state_dict', 'ema_state_dict', 'best_prec1', 'optimizer'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Shake(Function):\n",
    "    @classmethod\n",
    "    def forward(cls, ctx, inp1, inp2, training):\n",
    "        assert inp1.size() == inp2.size()\n",
    "        gate_size = [inp1.size()[0], *itertools.repeat(1, inp1.dim() - 1)]\n",
    "        gate = inp1.new(*gate_size)\n",
    "        if training:\n",
    "            gate.uniform_(0, 1)\n",
    "        else:\n",
    "            gate.fill_(0.5)\n",
    "        return inp1 * gate + inp2 * (1. - gate)\n",
    "\n",
    "    @classmethod\n",
    "    def backward(cls, ctx, grad_output):\n",
    "        grad_inp1 = grad_inp2 = grad_training = None\n",
    "        gate_size = [grad_output.size()[0], *itertools.repeat(1,\n",
    "                                                              grad_output.dim() - 1)]\n",
    "        gate = Variable(grad_output.data.new(*gate_size).uniform_(0, 1))\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_inp1 = grad_output * gate\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_inp2 = grad_output * (1 - gate)\n",
    "        assert not ctx.needs_input_grad[2]\n",
    "        return grad_inp1, grad_inp2, grad_training\n",
    "\n",
    "\n",
    "def shake(inp1, inp2, training=False):\n",
    "    return Shake.apply(inp1, inp2, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Acc@1 0.40625\n",
      "Acc@5 0.640625\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.29718440594059403\n",
      "Acc@5 0.5383663366336634\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3023165422885572\n",
      "Acc@5 0.5359141791044776\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30632267441860467\n",
      "Acc@5 0.5371677740863787\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.303927680798005\n",
      "Acc@5 0.5353413341645885\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3029565868263473\n",
      "Acc@5 0.5362400199600799\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30355657237936773\n",
      "Acc@5 0.5358257071547421\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3045203281027104\n",
      "Acc@5 0.5385164051355207\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.304229088639201\n",
      "Acc@5 0.5373946629213483\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3040545227524972\n",
      "Acc@5 0.5368860987791343\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30453125\n",
      "Acc@5 0.537390625\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.325.ckpt\" \n",
    "model = architectures.__dict__['cifar_shakeshake26']().to(device)\n",
    "model = load_weights(model, model_dir, state_dict=\"ema_state_dict\", cuda=True)\n",
    "\n",
    "n_samples = 0.\n",
    "n_correct_top_1 = 0\n",
    "n_correct_top_k = 0\n",
    "\n",
    "for i, (img, target) in enumerate(eval_loader):\n",
    "    img, target = img.to(device), target.to(device)\n",
    "    n_samples += BATCH_SIZE\n",
    "\n",
    "        # Forward\n",
    "    output = model(img)[0]\n",
    "\n",
    "        # Top 1 accuracy\n",
    "    pred_top_1 = torch.topk(output, k=1, dim=1)[1]\n",
    "    n_correct_top_1 += pred_top_1.eq(target.view_as(pred_top_1)).int().sum().item()\n",
    "\n",
    "        # Top k accuracy\n",
    "    pred_top_k = torch.topk(output, k=5, dim=1)[1]\n",
    "    target_top_k = target.view(-1, 1).expand(BATCH_SIZE, 5)\n",
    "    n_correct_top_k += pred_top_k.eq(target_top_k).int().sum().item()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"******************************\")\n",
    "        print(\"Acc@1\", n_correct_top_1/n_samples)\n",
    "        print(\"Acc@5\", n_correct_top_k/n_samples)\n",
    "        print(\"******************************\")\n",
    "    \n",
    "    # Accuracy\n",
    "top_1_acc = n_correct_top_1/n_samples\n",
    "top_k_acc = n_correct_top_k/n_samples\n",
    "\n",
    "print(\"******************************\")\n",
    "print(\"Acc@1\", top_1_acc)\n",
    "print(\"Acc@5\", top_k_acc)\n",
    "print(\"******************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
