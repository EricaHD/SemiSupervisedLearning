{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "from mean_teacher import datasets, architectures\n",
    "from mean_teacher.utils import *\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LOG = logging.getLogger('main')\n",
    "NO_LABEL = -1\n",
    "to_image = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = datasets.__dict__['sslMini']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model_arch, pretrained_model_path, state_dict, cuda=True):\n",
    "        # Load pretrained model\n",
    "        pretrained_model = torch.load(f=pretrained_model_path, map_location=\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in pretrained_model[state_dict].items():\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[name] = v\n",
    "\n",
    "        # Load pre-trained weights in current model\n",
    "        with torch.no_grad():\n",
    "            model_arch.load_state_dict(new_state_dict, strict=True)\n",
    "\n",
    "        # Debug loading\n",
    "        #print('Parameters found in pretrained model:')\n",
    "        pretrained_layers = new_state_dict.keys()\n",
    "        #for l in pretrained_layers:\n",
    "        #    print('\\t' + l)\n",
    "        #print('')\n",
    "\n",
    "        for name, module in model_arch.state_dict().items():\n",
    "            if name in pretrained_layers:\n",
    "                assert torch.equal(new_state_dict[name].cpu(), module.cpu())\n",
    "                #print('{} have been loaded correctly in current model.'.format(name))\n",
    "            else:\n",
    "                raise ValueError(\"state_dict() keys do not match\")\n",
    "                \n",
    "        return model_arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "evaldir = \"/scratch/ijh216/ssl_mini/supervised/val\"\n",
    "\n",
    "eval_loader = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(evaldir, dataset_config['eval_transformation']),\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2,\n",
    "                                              #pin_memory=True,\n",
    "                                              drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.325.ckpt\"\n",
    "log = torch.load(f=pretrained_model_path, map_location=\"cuda\" if False else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'arch', 'state_dict', 'ema_state_dict', 'best_prec1', 'optimizer'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.325.ckpt\" \n",
    "model = architectures.__dict__['cifar_shakeshake26']().to(device)\n",
    "model = load_weights(model, model_dir, state_dict=\"ema_state_dict\", cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(eval_loader, model, log, global_step, epoch, device=device):\n",
    "    class_criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=NO_LABEL).to(device)\n",
    "    meters = AverageMeterSet()\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (img, target) in enumerate(eval_loader):\n",
    "        meters.update('data_time', time.time() - end)\n",
    "        \n",
    "        img_var, target_var = img.to(device), target.to(device)\n",
    "        \n",
    "        minibatch_size = len(target_var)\n",
    "        labeled_minibatch_size = target_var.detach().ne(NO_LABEL).sum()\n",
    "        meters.update('labeled_minibatch_size', labeled_minibatch_size)\n",
    "\n",
    "        # compute output\n",
    "        output1, output2 = model(img_var)\n",
    "        softmax1, softmax2 = F.softmax(output1, dim=1), F.softmax(output2, dim=1)\n",
    "        class_loss = class_criterion(output1, target_var) / minibatch_size\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output1, target_var, topk=(1,5))\n",
    "        meters.update('class_loss', class_loss.item(), labeled_minibatch_size)\n",
    "        meters.update('top1', acc1, labeled_minibatch_size)\n",
    "        meters.update('error1', 100.0 - acc1, labeled_minibatch_size)\n",
    "        meters.update('top5', acc5, labeled_minibatch_size)\n",
    "        meters.update('error5', 100.0 - acc5, labeled_minibatch_size)\n",
    "\n",
    "        # measure elapsed time\n",
    "        meters.update('batch_time', time.time() - end)\n",
    "        end = time.time()\n",
    "        if i % 10 == 0:\n",
    "            LOG.info(\n",
    "                'Test: [{0}/{1}]\\t'\n",
    "                'Time {meters[batch_time]:.3f}\\t'\n",
    "                'Data {meters[data_time]:.3f}\\t'\n",
    "                'Class {meters[class_loss]:.4f}\\t'\n",
    "                'Acc@1 {meters[top1]:.3f}\\t'\n",
    "                'Acc@5 {meters[top5]:.3f}'.format(\n",
    "                    i, len(eval_loader), meters=meters))\n",
    "            \n",
    "        if i == 10:\n",
    "            break\n",
    "\n",
    "    LOG.info(' * Acc@1 {top1.avg:.3f}\\Acc@5 {top5.avg:.3f}'\n",
    "          .format(top1=meters['top1'], top5=meters['top5']))\n",
    "\n",
    "    return meters['top1'].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = validate(eval_loader, model, LOG, 325, 325, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0\n",
    "global best_acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = log['best_prec1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(res) > float(best_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(best_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(res) > log['best_prec1'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(float(res), log['best_prec1'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    labeled_minibatch_size = max(target.ne(NO_LABEL).sum(), 1e-8).item()\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True).item()\n",
    "        res.append(correct_k * (100.0 / labeled_minibatch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Acc@1 0.40625\n",
      "Acc@5 0.640625\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.29718440594059403\n",
      "Acc@5 0.5383663366336634\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3023165422885572\n",
      "Acc@5 0.5359141791044776\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30632267441860467\n",
      "Acc@5 0.5371677740863787\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.303927680798005\n",
      "Acc@5 0.5353413341645885\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3029565868263473\n",
      "Acc@5 0.5362400199600799\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30355657237936773\n",
      "Acc@5 0.5358257071547421\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3045203281027104\n",
      "Acc@5 0.5385164051355207\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.304229088639201\n",
      "Acc@5 0.5373946629213483\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3040545227524972\n",
      "Acc@5 0.5368860987791343\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30453125\n",
      "Acc@5 0.537390625\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.325.ckpt\" \n",
    "model = architectures.__dict__['cifar_shakeshake26']().to(device)\n",
    "model = load_weights(model, model_dir, state_dict=\"ema_state_dict\", cuda=True)\n",
    "\n",
    "n_samples = 0.\n",
    "n_correct_top_1 = 0\n",
    "n_correct_top_k = 0\n",
    "\n",
    "for i, (img, target) in enumerate(eval_loader):\n",
    "    img, target = img.to(device), target.to(device)\n",
    "    n_samples += BATCH_SIZE\n",
    "\n",
    "        # Forward\n",
    "    output = model(img)[0]\n",
    "\n",
    "        # Top 1 accuracy\n",
    "    pred_top_1 = torch.topk(output, k=1, dim=1)[1]\n",
    "    n_correct_top_1 += pred_top_1.eq(target.view_as(pred_top_1)).int().sum().item()\n",
    "\n",
    "        # Top k accuracy\n",
    "    pred_top_k = torch.topk(output, k=5, dim=1)[1]\n",
    "    target_top_k = target.view(-1, 1).expand(BATCH_SIZE, 5)\n",
    "    n_correct_top_k += pred_top_k.eq(target_top_k).int().sum().item()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"******************************\")\n",
    "        print(\"Acc@1\", n_correct_top_1/n_samples)\n",
    "        print(\"Acc@5\", n_correct_top_k/n_samples)\n",
    "        print(\"******************************\")\n",
    "    \n",
    "    # Accuracy\n",
    "top_1_acc = n_correct_top_1/n_samples\n",
    "top_k_acc = n_correct_top_k/n_samples\n",
    "\n",
    "print(\"******************************\")\n",
    "print(\"Acc@1\", top_1_acc)\n",
    "print(\"Acc@5\", top_k_acc)\n",
    "print(\"******************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100\n",
      "1 100\n",
      "2 100\n",
      "3 100\n",
      "4 100\n",
      "5 100\n",
      "6 100\n",
      "7 100\n",
      "8 100\n",
      "9 100\n",
      "10 100\n",
      "11 100\n",
      "12 100\n",
      "13 100\n",
      "14 100\n",
      "15 100\n",
      "16 100\n",
      "17 100\n",
      "18 100\n",
      "19 100\n",
      "20 100\n",
      "21 100\n",
      "22 100\n",
      "23 100\n",
      "24 100\n",
      "25 100\n",
      "26 100\n",
      "27 100\n",
      "28 100\n",
      "29 100\n",
      "30 100\n",
      "31 100\n",
      "32 100\n",
      "33 100\n",
      "34 100\n",
      "35 100\n",
      "36 100\n",
      "37 100\n",
      "38 100\n",
      "39 100\n",
      "40 100\n",
      "41 100\n",
      "42 100\n",
      "43 100\n",
      "44 100\n",
      "45 100\n",
      "46 100\n",
      "47 100\n",
      "48 100\n",
      "49 100\n",
      "50 100\n",
      "51 100\n",
      "52 100\n",
      "53 100\n",
      "54 100\n",
      "55 100\n",
      "56 100\n",
      "57 100\n",
      "58 100\n",
      "59 100\n",
      "60 100\n",
      "61 100\n",
      "62 100\n",
      "63 100\n",
      "64 100\n",
      "65 100\n",
      "66 100\n",
      "67 100\n",
      "68 100\n",
      "69 100\n",
      "70 100\n",
      "71 100\n",
      "72 100\n",
      "73 100\n",
      "74 100\n",
      "75 100\n",
      "76 100\n",
      "77 100\n",
      "78 100\n",
      "79 100\n",
      "80 100\n",
      "81 100\n",
      "82 100\n",
      "83 100\n",
      "84 100\n",
      "85 100\n",
      "86 100\n",
      "87 100\n",
      "88 100\n",
      "89 100\n",
      "90 100\n",
      "91 100\n",
      "92 100\n",
      "93 100\n",
      "94 100\n",
      "95 100\n",
      "96 100\n",
      "97 100\n",
      "98 100\n",
      "99 100\n",
      "100 100\n",
      "101 100\n",
      "102 100\n",
      "103 100\n",
      "104 100\n",
      "105 100\n",
      "106 100\n",
      "107 100\n",
      "108 100\n",
      "109 100\n",
      "110 100\n",
      "111 100\n",
      "112 100\n",
      "113 100\n",
      "114 100\n",
      "115 100\n",
      "116 100\n",
      "117 100\n",
      "118 100\n",
      "119 100\n",
      "120 100\n",
      "121 100\n",
      "122 100\n",
      "123 100\n",
      "124 100\n",
      "125 100\n",
      "126 100\n",
      "127 100\n",
      "128 100\n",
      "129 100\n",
      "130 100\n",
      "131 100\n",
      "132 100\n",
      "133 100\n",
      "134 100\n",
      "135 100\n",
      "136 100\n",
      "137 100\n",
      "138 100\n",
      "139 100\n",
      "140 100\n",
      "141 100\n",
      "142 100\n",
      "143 100\n",
      "144 100\n",
      "145 100\n",
      "146 100\n",
      "147 100\n",
      "148 100\n",
      "149 100\n",
      "150 100\n",
      "151 100\n",
      "152 100\n",
      "153 100\n",
      "154 100\n",
      "155 100\n",
      "156 100\n",
      "157 100\n",
      "158 100\n",
      "159 100\n",
      "160 100\n",
      "161 100\n",
      "162 100\n",
      "163 100\n",
      "164 100\n",
      "165 100\n",
      "166 100\n",
      "167 100\n",
      "168 100\n",
      "169 100\n",
      "170 100\n",
      "171 100\n",
      "172 100\n",
      "173 100\n",
      "174 100\n",
      "175 100\n",
      "176 100\n",
      "177 100\n",
      "178 100\n",
      "179 100\n",
      "180 100\n",
      "181 100\n",
      "182 100\n",
      "183 100\n",
      "184 100\n",
      "185 100\n",
      "186 100\n",
      "187 100\n",
      "188 100\n",
      "189 100\n",
      "190 100\n",
      "191 100\n",
      "192 100\n",
      "193 100\n",
      "194 100\n",
      "195 100\n",
      "196 100\n",
      "197 100\n",
      "198 100\n",
      "199 100\n",
      "200 100\n",
      "201 100\n",
      "202 100\n",
      "203 100\n",
      "204 100\n",
      "205 100\n",
      "206 100\n",
      "207 100\n",
      "208 100\n",
      "209 100\n",
      "210 100\n",
      "211 100\n",
      "212 100\n",
      "213 100\n",
      "214 100\n",
      "215 100\n",
      "216 100\n",
      "217 100\n",
      "218 100\n",
      "219 100\n",
      "220 100\n",
      "221 100\n",
      "222 100\n",
      "223 100\n",
      "224 100\n",
      "225 100\n",
      "226 100\n",
      "227 100\n",
      "228 100\n",
      "229 100\n",
      "230 100\n",
      "231 100\n",
      "232 100\n",
      "233 100\n",
      "234 100\n",
      "235 100\n",
      "236 100\n",
      "237 100\n",
      "238 100\n",
      "239 100\n",
      "240 100\n",
      "241 100\n",
      "242 100\n",
      "243 100\n",
      "244 100\n",
      "245 100\n",
      "246 100\n",
      "247 100\n",
      "248 100\n",
      "249 100\n",
      "250 100\n",
      "251 100\n",
      "252 100\n",
      "253 100\n",
      "254 100\n",
      "255 100\n",
      "256 100\n",
      "257 100\n",
      "258 100\n",
      "259 100\n",
      "260 100\n",
      "261 100\n",
      "262 100\n",
      "263 100\n",
      "264 100\n",
      "265 100\n",
      "266 100\n",
      "267 100\n",
      "268 100\n",
      "269 100\n",
      "270 100\n",
      "271 100\n",
      "272 100\n",
      "273 100\n",
      "274 100\n",
      "275 100\n",
      "276 100\n",
      "277 100\n",
      "278 100\n",
      "279 100\n",
      "280 100\n",
      "281 100\n",
      "282 100\n",
      "283 100\n",
      "284 100\n",
      "285 100\n",
      "286 100\n",
      "287 100\n",
      "288 100\n",
      "289 100\n",
      "290 100\n",
      "291 100\n",
      "292 100\n",
      "293 100\n",
      "294 100\n",
      "295 100\n",
      "296 100\n",
      "297 100\n",
      "298 100\n",
      "299 100\n",
      "300 100\n",
      "301 100\n",
      "302 100\n",
      "303 100\n",
      "304 100\n",
      "305 100\n",
      "306 100\n",
      "307 100\n",
      "308 100\n",
      "309 100\n",
      "310 100\n",
      "311 100\n",
      "312 100\n",
      "313 100\n",
      "314 100\n",
      "315 100\n",
      "316 100\n",
      "317 100\n",
      "318 100\n",
      "319 100\n",
      "320 100\n",
      "321 100\n",
      "322 100\n",
      "323 100\n",
      "324 100\n",
      "325 100\n",
      "326 100\n",
      "327 100\n",
      "328 100\n",
      "329 100\n",
      "330 100\n",
      "331 100\n",
      "332 100\n",
      "333 100\n",
      "334 100\n",
      "335 100\n",
      "336 100\n",
      "337 100\n",
      "338 100\n",
      "339 100\n",
      "340 100\n",
      "341 100\n",
      "342 100\n",
      "343 100\n",
      "344 100\n",
      "345 100\n",
      "346 100\n",
      "347 100\n",
      "348 100\n",
      "349 100\n",
      "350 100\n",
      "351 100\n",
      "352 100\n",
      "353 100\n",
      "354 100\n",
      "355 100\n",
      "356 100\n",
      "357 100\n",
      "358 100\n",
      "359 100\n",
      "360 100\n",
      "361 100\n",
      "362 100\n",
      "363 100\n",
      "364 100\n",
      "365 100\n",
      "366 100\n",
      "367 100\n",
      "368 100\n",
      "369 100\n",
      "370 100\n",
      "371 100\n",
      "372 100\n",
      "373 100\n",
      "374 100\n",
      "375 100\n",
      "376 100\n",
      "377 100\n",
      "378 100\n",
      "379 100\n",
      "380 100\n",
      "381 100\n",
      "382 100\n",
      "383 100\n",
      "384 100\n",
      "385 100\n",
      "386 100\n",
      "387 100\n",
      "388 100\n",
      "389 100\n",
      "390 100\n",
      "391 100\n",
      "392 100\n",
      "393 100\n",
      "394 100\n",
      "395 100\n",
      "396 100\n",
      "397 100\n",
      "398 100\n",
      "399 100\n",
      "400 100\n",
      "401 100\n",
      "402 100\n",
      "403 100\n",
      "404 100\n",
      "405 100\n",
      "406 100\n",
      "407 100\n",
      "408 100\n",
      "409 100\n",
      "410 100\n",
      "411 100\n",
      "412 100\n",
      "413 100\n",
      "414 100\n",
      "415 100\n",
      "416 100\n",
      "417 100\n",
      "418 100\n",
      "419 100\n",
      "420 100\n",
      "421 100\n",
      "422 100\n",
      "423 100\n",
      "424 100\n",
      "425 100\n",
      "426 100\n",
      "427 100\n",
      "428 100\n",
      "429 100\n",
      "430 100\n",
      "431 100\n",
      "432 100\n",
      "433 100\n",
      "434 100\n",
      "435 100\n",
      "436 100\n",
      "437 100\n",
      "438 100\n",
      "439 100\n",
      "440 100\n",
      "441 100\n",
      "442 100\n",
      "443 100\n",
      "444 100\n",
      "445 100\n",
      "446 100\n",
      "447 100\n",
      "448 100\n",
      "449 100\n",
      "450 100\n",
      "451 100\n",
      "452 100\n",
      "453 100\n",
      "454 100\n",
      "455 100\n",
      "456 100\n",
      "457 100\n",
      "458 100\n",
      "459 100\n",
      "460 100\n",
      "461 100\n",
      "462 100\n",
      "463 100\n",
      "464 100\n",
      "465 100\n",
      "466 100\n",
      "467 100\n",
      "468 100\n",
      "469 100\n",
      "470 100\n",
      "471 100\n",
      "472 100\n",
      "473 100\n",
      "474 100\n",
      "475 100\n",
      "476 100\n",
      "477 100\n",
      "478 100\n",
      "479 100\n",
      "480 100\n",
      "481 100\n",
      "482 100\n",
      "483 100\n",
      "484 100\n",
      "485 100\n",
      "486 100\n",
      "487 100\n",
      "488 100\n",
      "489 100\n",
      "490 100\n",
      "491 100\n",
      "492 100\n",
      "493 100\n",
      "494 100\n",
      "495 100\n",
      "496 100\n",
      "497 100\n",
      "498 100\n",
      "499 100\n",
      "500 100\n",
      "501 100\n",
      "502 100\n",
      "503 100\n",
      "504 100\n",
      "505 100\n",
      "506 100\n",
      "507 100\n",
      "508 100\n",
      "509 100\n",
      "510 100\n",
      "511 100\n"
     ]
    }
   ],
   "source": [
    "for j, i in enumerate(os.listdir(\"/scratch/ijh216/ssl2\"+'/unsupervised')):\n",
    "    print(j, len(os.listdir(\"/scratch/ijh216/ssl2\"+'/unsupervised/'+i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = eval_loader.dataset.imgs[0][0]\n",
    "img = eval_loader.dataset[0][0].unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for ckpt in range(0, 325, 5):\n",
    "\n",
    "    model_dir = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.{}.ckpt\".format(ckpt) \n",
    "    model = architectures.__dict__['cifar_shakeshake26']().to(device)\n",
    "    model = load_weights(model, model_dir, state_dict=\"ema_state_dict\", cuda=False)\n",
    "\n",
    "\n",
    "    output = F.softmax(model(img)[0], dim=1)\n",
    "    labels.append(output)\n",
    "\n",
    "labels = torch.cat(labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.cat(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([130, 1000])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((labels, labels)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
