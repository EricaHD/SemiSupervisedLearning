{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "from mean_teacher import datasets, architectures\n",
    "from mean_teacher.utils import *\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LOG = logging.getLogger('main')\n",
    "NO_LABEL = -1\n",
    "to_image = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = datasets.__dict__['sslMini']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model_arch, pretrained_model_path, state_dict, cuda=True):\n",
    "        # Load pretrained model\n",
    "        pretrained_model = torch.load(f=pretrained_model_path, map_location=\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "        from collections import OrderedDict\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in pretrained_model[state_dict].items():\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[name] = v\n",
    "\n",
    "        # Load pre-trained weights in current model\n",
    "        with torch.no_grad():\n",
    "            model_arch.load_state_dict(new_state_dict, strict=True)\n",
    "\n",
    "        # Debug loading\n",
    "        #print('Parameters found in pretrained model:')\n",
    "        pretrained_layers = new_state_dict.keys()\n",
    "        #for l in pretrained_layers:\n",
    "        #    print('\\t' + l)\n",
    "        #print('')\n",
    "\n",
    "        for name, module in model_arch.state_dict().items():\n",
    "            if name in pretrained_layers:\n",
    "                assert torch.equal(new_state_dict[name].cpu(), module.cpu())\n",
    "                #print('{} have been loaded correctly in current model.'.format(name))\n",
    "            else:\n",
    "                raise ValueError(\"state_dict() keys do not match\")\n",
    "                \n",
    "        return model_arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "evaldir = \"/scratch/ijh216/ssl_mini/supervised/val\"\n",
    "\n",
    "eval_loader = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(evaldir, dataset_config['eval_transformation']),\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2,\n",
    "                                              #pin_memory=True,\n",
    "                                              drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.325.ckpt\"\n",
    "log = torch.load(f=pretrained_model_path, map_location=\"cuda\" if False else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'arch', 'state_dict', 'ema_state_dict', 'best_prec1', 'optimizer'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.325.ckpt\" \n",
    "model = architectures.__dict__['cifar_shakeshake26']().to(device)\n",
    "model = load_weights(model, model_dir, state_dict=\"ema_state_dict\", cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(eval_loader, model, log, global_step, epoch, device=device):\n",
    "    class_criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=NO_LABEL).to(device)\n",
    "    meters = AverageMeterSet()\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (img, target) in enumerate(eval_loader):\n",
    "        meters.update('data_time', time.time() - end)\n",
    "        \n",
    "        img_var, target_var = img.to(device), target.to(device)\n",
    "        \n",
    "        minibatch_size = len(target_var)\n",
    "        labeled_minibatch_size = target_var.detach().ne(NO_LABEL).sum()\n",
    "        meters.update('labeled_minibatch_size', labeled_minibatch_size)\n",
    "\n",
    "        # compute output\n",
    "        output1, output2 = model(img_var)\n",
    "        softmax1, softmax2 = F.softmax(output1, dim=1), F.softmax(output2, dim=1)\n",
    "        class_loss = class_criterion(output1, target_var) / minibatch_size\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output1, target_var, topk=(1,5))\n",
    "        meters.update('class_loss', class_loss.item(), labeled_minibatch_size)\n",
    "        meters.update('top1', acc1, labeled_minibatch_size)\n",
    "        meters.update('error1', 100.0 - acc1, labeled_minibatch_size)\n",
    "        meters.update('top5', acc5, labeled_minibatch_size)\n",
    "        meters.update('error5', 100.0 - acc5, labeled_minibatch_size)\n",
    "\n",
    "        # measure elapsed time\n",
    "        meters.update('batch_time', time.time() - end)\n",
    "        end = time.time()\n",
    "        if i % 10 == 0:\n",
    "            LOG.info(\n",
    "                'Test: [{0}/{1}]\\t'\n",
    "                'Time {meters[batch_time]:.3f}\\t'\n",
    "                'Data {meters[data_time]:.3f}\\t'\n",
    "                'Class {meters[class_loss]:.4f}\\t'\n",
    "                'Acc@1 {meters[top1]:.3f}\\t'\n",
    "                'Acc@5 {meters[top5]:.3f}'.format(\n",
    "                    i, len(eval_loader), meters=meters))\n",
    "            \n",
    "        if i == 10:\n",
    "            break\n",
    "\n",
    "    LOG.info(' * Acc@1 {top1.avg:.3f}\\Acc@5 {top5.avg:.3f}'\n",
    "          .format(top1=meters['top1'], top5=meters['top5']))\n",
    "\n",
    "    return meters['top1'].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = validate(eval_loader, model, LOG, 325, 325, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log['best_prec1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(res) > log['best_prec1'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(float(res), log['best_prec1'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    labeled_minibatch_size = max(target.ne(NO_LABEL).sum(), 1e-8).item()\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True).item()\n",
    "        res.append(correct_k * (100.0 / labeled_minibatch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Acc@1 0.40625\n",
      "Acc@5 0.640625\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.29718440594059403\n",
      "Acc@5 0.5383663366336634\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3023165422885572\n",
      "Acc@5 0.5359141791044776\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30632267441860467\n",
      "Acc@5 0.5371677740863787\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.303927680798005\n",
      "Acc@5 0.5353413341645885\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3029565868263473\n",
      "Acc@5 0.5362400199600799\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30355657237936773\n",
      "Acc@5 0.5358257071547421\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3045203281027104\n",
      "Acc@5 0.5385164051355207\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.304229088639201\n",
      "Acc@5 0.5373946629213483\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.3040545227524972\n",
      "Acc@5 0.5368860987791343\n",
      "******************************\n",
      "******************************\n",
      "Acc@1 0.30453125\n",
      "Acc@5 0.537390625\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/scratch/ijh216/ssl/ssl_shake_mini_augment/2019-05-06_18-04-18/10/transient/checkpoint.325.ckpt\" \n",
    "model = architectures.__dict__['cifar_shakeshake26']().to(device)\n",
    "model = load_weights(model, model_dir, state_dict=\"ema_state_dict\", cuda=True)\n",
    "\n",
    "n_samples = 0.\n",
    "n_correct_top_1 = 0\n",
    "n_correct_top_k = 0\n",
    "\n",
    "for i, (img, target) in enumerate(eval_loader):\n",
    "    img, target = img.to(device), target.to(device)\n",
    "    n_samples += BATCH_SIZE\n",
    "\n",
    "        # Forward\n",
    "    output = model(img)[0]\n",
    "\n",
    "        # Top 1 accuracy\n",
    "    pred_top_1 = torch.topk(output, k=1, dim=1)[1]\n",
    "    n_correct_top_1 += pred_top_1.eq(target.view_as(pred_top_1)).int().sum().item()\n",
    "\n",
    "        # Top k accuracy\n",
    "    pred_top_k = torch.topk(output, k=5, dim=1)[1]\n",
    "    target_top_k = target.view(-1, 1).expand(BATCH_SIZE, 5)\n",
    "    n_correct_top_k += pred_top_k.eq(target_top_k).int().sum().item()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"******************************\")\n",
    "        print(\"Acc@1\", n_correct_top_1/n_samples)\n",
    "        print(\"Acc@5\", n_correct_top_k/n_samples)\n",
    "        print(\"******************************\")\n",
    "    \n",
    "    # Accuracy\n",
    "top_1_acc = n_correct_top_1/n_samples\n",
    "top_k_acc = n_correct_top_k/n_samples\n",
    "\n",
    "print(\"******************************\")\n",
    "print(\"Acc@1\", top_1_acc)\n",
    "print(\"Acc@5\", top_k_acc)\n",
    "print(\"******************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
